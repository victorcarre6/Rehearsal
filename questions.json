{
  "themes": [
    {
      "id": "fondamentaux",
      "name": "Concepts Fondamentaux",
      "questions": [
        {
          "id": 1,
          "question": "What is Data Science?",
          "answer": "Data Science is a **blend of various tools, algorithms, and machine learning principles** with the goal to **discover hidden patterns from the raw data**. The answer lies in the difference between **explaining** and **predicting**."
        },
        {
          "id": 2,
          "question": "What is Selection Bias?",
          "answer": "Selection bias is a kind of error that occurs when the researcher decides who is going to be studied. It is usually associated with research where the selection of participants isn't random. It is sometimes referred to as the selection effect. It is the distortion of statistical analysis, resulting from the method of collecting samples.\n\n**Types of selection bias:**\n\n1. **Sampling bias**: Systematic error due to a non-random sample of a population causing some members to be less likely to be included than others\n2. **Time interval**: A trial may be terminated early at an extreme value, but the extreme value is likely to be reached by the variable with the largest variance\n3. **Data**: When specific subsets of data are chosen to support a conclusion or rejection of bad data on arbitrary grounds\n4. **Attrition**: Selection bias caused by attrition (loss of participants) discounting trial subjects/tests that did not run to completion"
        },
        {
          "id": 3,
          "question": "What is bias-variance trade-off?",
          "answer": "**Bias**: Error introduced in your model due to oversimplification of the machine learning algorithm. It can lead to underfitting.\n\n- Low bias algorithms: Decision Trees, k-NN and SVM\n- High bias algorithms: Linear Regression, Logistic Regression\n\n**Variance**: Error introduced due to complex machine learning algorithm, your model learns noise from the training data and performs badly on test data. It can lead to overfitting.\n\n**Bias-Variance trade-off**: The goal of any supervised machine learning algorithm is to have low bias and low variance to achieve good prediction performance. There is no escaping the relationship between bias and variance - increasing bias will decrease variance and vice versa."
        },
        {
          "id": 4,
          "question": "What is a confusion matrix?",
          "answer": "The confusion matrix is a 2X2 table that contains 4 outputs provided by the binary classifier:\n\n- **True-positive (TP)**: Correct positive prediction\n- **False-positive (FP)**: Incorrect positive prediction\n- **True-negative (TN)**: Correct negative prediction\n- **False-negative (FN)**: Incorrect negative prediction\n\n**Basic measures derived:**\n\n1. Error Rate = (FP+FN)/(P+N)\n2. Accuracy = (TP+TN)/(P+N)\n3. Sensitivity (Recall) = TP/P\n4. Specificity = TN/N\n5. Precision = TP/(TP+FP)\n6. F-Score = (1+b)(PREC.REC)/(b²PREC+REC)"
        }
      ]
    },
    {
      "id": "statistiques",
      "name": "Statistiques",
      "questions": [
        {
          "id": 5,
          "question": "What is the difference between 'long' and 'wide' format data?",
          "answer": "In the **wide-format**, a subject's repeated responses will be in a single row, and each response is in a separate column.\n\nIn the **long-format**, each row is a one-time point per subject.\n\nYou can recognize data in wide format by the fact that columns generally represent groups."
        },
        {
          "id": 6,
          "question": "What do you understand by the term Normal Distribution?",
          "answer": "Data distributed around a central value without any bias to the left or right reaches normal distribution in the form of a bell-shaped curve.\n\n**Properties of Normal Distribution:**\n\n1. Unimodal - one mode\n2. Symmetrical - left and right halves are mirror images\n3. Bell-shaped - maximum height (mode) at the mean\n4. Mean, Mode, and Median are all located in the center\n5. Asymptotic"
        },
        {
          "id": 7,
          "question": "What is correlation and covariance in statistics?",
          "answer": "**Correlation**: The best technique for measuring and estimating the quantitative relationship between two variables. Correlation measures how strongly two variables are related.\n\n**Covariance**: A measure that indicates the extent to which two random variables change in cycle. It explains the systematic relation between a pair of random variables, wherein changes in one variable reciprocal by a corresponding change in another variable."
        },
        {
          "id": 8,
          "question": "What is the difference between Point Estimates and Confidence Interval?",
          "answer": "**Point Estimation**: Gives us a particular value as an estimate of a population parameter. Method of Moments and Maximum Likelihood estimator methods are used.\n\n**Confidence Interval**: Gives us a range of values which is likely to contain the population parameter. Generally preferred as it tells us how likely this interval is to contain the population parameter. The probability is called Confidence Level (1 - alpha)."
        },
        {
          "id": 9,
          "question": "What is the goal of A/B Testing?",
          "answer": "A/B Testing is a hypothesis testing for a randomized experiment with two variables A and B.\n\nThe goal is to identify any changes to the web page to maximize or increase the outcome of interest. It can be used to test everything from website copy to sales emails to search ads.\n\nExample: identifying the click-through rate for a banner ad."
        },
        {
          "id": 10,
          "question": "What is p-value?",
          "answer": "p-value is a number between 0 and 1 that helps determine the strength of your results in hypothesis testing. The claim on trial is called the Null Hypothesis.\n\n- **Low p-value (≤ 0.05)**: Strong evidence against the null hypothesis - reject it\n- **High p-value (≥ 0.05)**: Strong evidence for the null hypothesis - accept it\n- **p-value = 0.05**: Hypothesis could go either way"
        },
        {
          "id": 11,
          "question": "In any 15-minute interval, there is a 20% probability that you will see at least one shooting star. What is the probability that you see at least one shooting star in the period of an hour?",
          "answer": "P(not seeing any star in 15 min) = 1 - 0.2 = 0.8\n\nP(not seeing any star in 1 hour) = (0.8)^4 = 0.4096\n\nP(seeing at least one star in 1 hour) = 1 - 0.4096 = **0.5904**"
        },
        {
          "id": 12,
          "question": "How can you generate a random number between 1–7 with only a die?",
          "answer": "- Roll the die twice to get 36 different outcomes\n- Reduce 36 to 35 (divisible by 7) by excluding combination (6,6)\n- If (6,6) appears, roll again\n- Divide remaining combinations from (1,1) to (6,5) into 7 parts of 5 each\n- All seven sets of outcomes are equally likely"
        },
        {
          "id": 13,
          "question": "A certain couple tells you that they have two children, at least one of which is a girl. What is the probability that they have two girls?",
          "answer": "For two children, there are 4 possibilities: BB, BG, GB, GG\n\nExcluding BB (since at least one is a girl), we have: BG, GB, GG\n\nP(two girls | at least one girl) = **1/3**"
        },
        {
          "id": 14,
          "question": "A jar has 1000 coins, of which 999 are fair and 1 is double headed. Pick a coin at random, and toss it 10 times. Given that you see 10 heads, what is the probability that the next toss of that coin is also a head?",
          "answer": "P(fair coin) = 999/1000 = 0.999\nP(unfair coin) = 1/1000 = 0.001\n\nP(10 heads | fair) = 0.999 × (1/2)^10 = 0.000976\nP(10 heads | unfair) = 0.001 × 1 = 0.001\n\nP(fair | 10 heads) = 0.000976 / 0.001976 = 0.4939\nP(unfair | 10 heads) = 0.001 / 0.001976 = 0.5061\n\nP(next head) = 0.4939 × 0.5 + 0.5061 × 1 = **0.7531**"
        },
        {
          "id": 15,
          "question": "What do you understand by statistical power of sensitivity and how do you calculate it?",
          "answer": "Sensitivity is commonly used to validate the accuracy of a classifier (Logistic, SVM, Random Forest etc.).\n\nSensitivity = \"Predicted True events / Total events\"\n\n**Formula**: Sensitivity = True Positives / Positives in Actual Dependent Variable"
        },
        {
          "id": 16,
          "question": "Why Is Re-sampling Done?",
          "answer": "Resampling is done for:\n\n- Estimating the accuracy of sample statistics by using subsets of accessible data or drawing randomly with replacement\n- Substituting labels on data points when performing significance tests\n- Validating models by using random subsets (bootstrapping, cross-validation)"
        },
        {
          "id": 17,
          "question": "What are the differences between over-fitting and under-fitting?",
          "answer": "**Overfitting**: A statistical model describes random error or noise instead of the underlying relationship. Occurs when a model is excessively complex (too many parameters relative to observations). Results in poor predictive performance.\n\n**Underfitting**: A model cannot capture the underlying trend of the data. Example: fitting a linear model to non-linear data. Also results in poor predictive performance."
        },
        {
          "id": 18,
          "question": "How to combat Overfitting and Underfitting?",
          "answer": "- Resample the data to estimate model accuracy (k-fold cross-validation)\n- Have a validation dataset to evaluate the model"
        },
        {
          "id": 19,
          "question": "What is regularisation? Why is it useful?",
          "answer": "Regularisation is the process of adding a tuning parameter to a model to induce smoothness in order to prevent overfitting.\n\nThis is done by adding a constant multiple to an existing weight vector, often L1 (Lasso) or L2 (Ridge).\n\nThe model predictions should then minimize the loss function calculated on the regularized training set."
        },
        {
          "id": 20,
          "question": "What Is the Law of Large Numbers?",
          "answer": "A theorem that describes the result of performing the same experiment a large number of times.\n\nIt forms the basis of frequency-style thinking and states that the sample means, sample variance, and sample standard deviation converge to what they are trying to estimate."
        },
        {
          "id": 21,
          "question": "What Are Confounding Variables?",
          "answer": "A confounder is a variable that influences both the dependent variable and independent variable.\n\n**Example**: If researching whether lack of exercise leads to weight gain:\n\n- Independent variable: lack of exercise\n- Dependent variable: weight gain\n- Confounding variable: age of the subject"
        },
        {
          "id": 22,
          "question": "What Are the Types of Biases That Can Occur During Sampling?",
          "answer": "- Selection bias\n- Under coverage bias\n- Survivorship bias"
        },
        {
          "id": 23,
          "question": "What is Survivorship Bias?",
          "answer": "The logical error of focusing on aspects that support surviving some process and casually overlooking those that did not work because of their lack of prominence.\n\nThis can lead to wrong conclusions in numerous different ways."
        },
        {
          "id": 24,
          "question": "What is selection Bias?",
          "answer": "Selection bias occurs when the sample obtained is not representative of the population intended to be analysed."
        },
        {
          "id": 25,
          "question": "Explain how a ROC curve works?",
          "answer": "The ROC curve is a graphical representation of the contrast between true positive rates and false-positive rates at various thresholds.\n\nIt is often used as a proxy for the trade-off between sensitivity (true positive rate) and false-positive rate."
        },
        {
          "id": 26,
          "question": "What is TF/IDF vectorization?",
          "answer": "TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that reflects how important a word is to a document in a collection or corpus.\n\nIt is often used as a weighting factor in information retrieval and text mining.\n\nThe TF-IDF value increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
        },
        {
          "id": 27,
          "question": "Why we generally use Softmax non-linearity function as last operation in-network?",
          "answer": "Because it takes in a vector of real numbers and returns a probability distribution.\n\nEach element of the output is non-negative and the sum over all components is 1.\n\nSoftmax(x)_i = e^(x_i) / Σ(e^(x_j))"
        }
      ]
    },
    {
      "id": "analyse",
      "name": "Analyse de Données",
      "questions": [
        {
          "id": 28,
          "question": "Python or R – Which one would you prefer for text analytics?",
          "answer": "Python is preferred because:\n\n- Python has Pandas library with easy-to-use data structures and high-performance data analysis tools\n- R is more suitable for machine learning than just text analysis\n- Python performs faster for all types of text analytics"
        },
        {
          "id": 29,
          "question": "How does data cleaning play a vital role in the analysis?",
          "answer": "- Cleaning data from multiple sources helps transform it into a format that data analysts can work with\n- Data Cleaning helps increase the accuracy of machine learning models\n- It's a cumbersome process - time increases exponentially with more data sources\n- It might take up to 80% of the time for just cleaning data"
        },
        {
          "id": 30,
          "question": "Differentiate between univariate, bivariate and multivariate analysis.",
          "answer": "**Univariate**: Involves only one variable. Purpose is to describe the data and find patterns using mean, median, mode, dispersion, etc.\n\n**Bivariate**: Involves two different variables. Deals with causes and relationships between the two variables.\n\n**Multivariate**: Involves three or more variables. Similar to bivariate but contains more than one dependent variable."
        },
        {
          "id": 31,
          "question": "Explain Star Schema.",
          "answer": "A traditional database schema with a central table. Satellite tables map IDs to physical names or descriptions and can be connected to the central fact table using ID fields.\n\nThese tables are known as lookup tables and are principally useful in real-time applications as they save memory. Sometimes involves several layers of summarization to recover information faster."
        },
        {
          "id": 32,
          "question": "What is Cluster Sampling?",
          "answer": "A technique used when it becomes difficult to study the target population spread across a wide area and simple random sampling cannot be applied.\n\nCluster Sample is a probability sample where each sampling unit is a collection or cluster of elements.\n\n**Example**: Dividing Japan into cities (clusters) to survey academic performance of high school students."
        },
        {
          "id": 33,
          "question": "What is Systematic Sampling?",
          "answer": "A statistical technique where elements are selected from an ordered sampling frame.\n\nThe list is progressed in a circular manner - once you reach the end, it continues from the top again.\n\nThe best example is the equal probability method."
        },
        {
          "id": 34,
          "question": "What are Eigenvectors and Eigenvalues?",
          "answer": "**Eigenvectors**: Used for understanding linear transformations. Usually calculated for correlation or covariance matrices. They are the directions along which a linear transformation acts by flipping, compressing, or stretching.\n\n**Eigenvalues**: The strength of the transformation in the direction of eigenvector, or the factor by which the compression occurs."
        },
        {
          "id": 35,
          "question": "Can you cite some examples where a false positive is important than a false negative?",
          "answer": "**Example 1 (Medical)**: A patient tested positive for cancer but doesn't actually have it. Starting chemotherapy would damage healthy cells and might lead to severe diseases.\n\n**Example 2 (E-commerce)**: Sending $1000 gift vouchers to customers wrongly marked as $10,000+ purchasers causes financial loss."
        },
        {
          "id": 36,
          "question": "Can you cite some examples where a false negative important than a false positive?",
          "answer": "**Example 1 (Airport Security)**: A true threat flagged as non-threat by the predictive model\n\n**Example 2 (Legal)**: A judge decides to make a criminal go free\n\n**Example 3 (Personal)**: Rejecting to marry a good person based on a predictive model"
        },
        {
          "id": 37,
          "question": "Can you cite some examples where both false positive and false negatives are equally important?",
          "answer": "**Banking industry**: Giving loans is the primary source of making money, but repayment rate is crucial.\n\nBanks don't want to lose good customers (false negative) and don't want to acquire bad customers (false positive). Both become very important to measure."
        },
        {
          "id": 38,
          "question": "Can you explain the difference between a Validation Set and a Test Set?",
          "answer": "**Validation Set**: Part of the training set, used for parameter selection and to avoid overfitting.\n\n**Test Set**: Used for testing or evaluating the performance of a trained model.\n\nTraining set fits parameters (weights), test set assesses performance (predictive power and generalization)."
        },
        {
          "id": 39,
          "question": "Explain cross-validation.",
          "answer": "A model validation technique for evaluating how the outcomes of statistical analysis will generalize to an independent dataset.\n\nThe goal is to test the model in the training phase using a validation data set to limit problems like overfitting and get insight on how the model will generalize."
        }
      ]
    },
    {
      "id": "ml",
      "name": "Machine Learning",
      "questions": [
        {
          "id": 40,
          "question": "What is Machine Learning?",
          "answer": "Machine Learning explores the study and construction of algorithms that can learn from and make predictions on data.\n\nClosely related to computational statistics. Used to devise complex models and algorithms for predictive analytics."
        },
        {
          "id": 41,
          "question": "What is Supervised Learning?",
          "answer": "The machine learning task of inferring a function from labeled training data.\n\n**Algorithms**: Support Vector Machines, Regression, Naive Bayes, Decision Trees, K-nearest Neighbor, Neural Networks\n\n**Example**: Fruit classifier with labels \"this is an orange, this is an apple, this is a banana\""
        },
        {
          "id": 42,
          "question": "What is Unsupervised learning?",
          "answer": "A type of machine learning algorithm used to draw inferences from datasets consisting of input data without labelled responses.\n\n**Algorithms**: Clustering, Anomaly Detection, Neural Networks, Latent Variable Models\n\n**Example**: Fruit clustering as \"fruits with soft skin\", \"fruits with shiny hard skin\", \"elongated yellow fruits\""
        },
        {
          "id": 43,
          "question": "What are the various classification algorithms?",
          "answer": "- Linear\n- Decision Trees\n- SVM\n- Kernel Estimation\n- Neural Networks\n- Quadratic\n- Naive Bayes\n- Logistic Regression\n- Recurrent Neural Network (RNN)\n- Modular Neural Network"
        },
        {
          "id": 44,
          "question": "What is 'Naive' in a Naive Bayes?",
          "answer": "The Naive Bayes Algorithm is based on Bayes' theorem, which describes the probability of an event based on prior knowledge of conditions.\n\nThe Algorithm is 'naive' because it makes assumptions that may or may not turn out to be correct."
        },
        {
          "id": 45,
          "question": "Explain SVM algorithm in detail.",
          "answer": "SVM (Support Vector Machine) is a supervised machine learning algorithm used for both Regression and Classification.\n\nIf you have n features, SVM tries to plot it in n-dimensional space with each feature being a coordinate value.\n\nSVM uses hyperplanes to separate out different classes based on the provided kernel function."
        },
        {
          "id": 46,
          "question": "What are the support vectors in SVM?",
          "answer": "Support vectors are the data points closest to the classifier (hyperplane).\n\nThe distance from the classifier to these closest data points is marked by thinner lines.\n\nThe distance between the two thin lines is called the margin."
        },
        {
          "id": 47,
          "question": "What are the different kernels in SVM?",
          "answer": "1. Linear Kernel\n2. Polynomial kernel\n3. Radial basis kernel\n4. Sigmoid kernel"
        },
        {
          "id": 48,
          "question": "Explain Decision Tree algorithm in detail.",
          "answer": "A supervised machine learning algorithm mainly used for Regression and Classification.\n\nIt breaks down a data set into smaller subsets while an associated decision tree is incrementally developed.\n\nThe final result is a tree with decision nodes and leaf nodes. Can handle both categorical and numerical data."
        },
        {
          "id": 49,
          "question": "What are Entropy and Information gain in Decision tree algorithm?",
          "answer": "The core algorithm for building a decision tree is called ID3, which uses Entropy and Information Gain.\n\n**Entropy**: Checks homogeneity of a sample. If completely homogeneous, entropy = 0. If equally divided, entropy = 1.\n\n**Information Gain**: Based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is about finding attributes with the highest information gain."
        },
        {
          "id": 50,
          "question": "What is pruning in Decision Tree?",
          "answer": "Pruning is a technique that reduces the size of decision trees by removing sections that provide little power to classify instances.\n\nWhen we remove sub-nodes of a decision node, this process is called pruning (opposite process of splitting)."
        }
      ]
    },
    {
      "id": "dl",
      "name": "Deep Learning",
      "questions": [
        {
          "id": 69,
          "question": "What do you mean by Deep Learning?",
          "answer": "Deep Learning is a paradigm of machine learning which has shown incredible promise in recent years.\n\nThis is because Deep Learning shows a great analogy with the functioning of the human brain."
        },
        {
          "id": 70,
          "question": "What is the difference between machine learning and deep learning?",
          "answer": "**Machine learning**: A field of computer science that gives computers the ability to learn without being explicitly programmed. Categories: Supervised, Unsupervised, Reinforcement learning.\n\n**Deep Learning**: A subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks."
        },
        {
          "id": 71,
          "question": "What, in your opinion, is the reason for the popularity of Deep Learning in recent times?",
          "answer": "Two main reasons:\n\n1. The increase in the amount of data generated through various sources\n2. The growth in hardware resources (GPUs) required to run these models\n\nGPUs are multiple times faster and help build bigger and deeper models in less time."
        },
        {
          "id": 72,
          "question": "What is reinforcement learning?",
          "answer": "Learning what to do and how to map situations to actions to maximise the numerical reward signal.\n\nThe learner is not told which action to take but must discover which action yields maximum reward.\n\nInspired by human learning, based on the reward/penalty mechanism."
        },
        {
          "id": 73,
          "question": "What are Artificial Neural Networks?",
          "answer": "A specific set of algorithms that have revolutionized machine learning, inspired by biological neural networks.\n\nNeural Networks can adapt to changing input so the network generates the best possible result without needing to redesign the output criteria."
        },
        {
          "id": 74,
          "question": "Describe the structure of Artificial Neural Networks?",
          "answer": "Works on the same principle as biological Neural Networks.\n\nConsists of inputs which get processed with weighted sums and Bias, with the help of Activation Functions."
        },
        {
          "id": 75,
          "question": "How Are Weights Initialized in a Network?",
          "answer": "**Initialize to 0**: Makes model similar to a linear model. All neurons perform same operation - makes deep net useless.\n\n**Initialize randomly**: Weights assigned randomly very close to 0. Gives better accuracy since every neuron performs different computations. Most commonly used method."
        },
        {
          "id": 76,
          "question": "What Is the Cost Function?",
          "answer": "Also referred to as \"loss\" or \"error,\" it's a measure to evaluate how good your model's performance is.\n\nUsed to compute the error of the output layer during backpropagation, which is then used during training functions."
        },
        {
          "id": 77,
          "question": "What Are Hyperparameters?",
          "answer": "Parameters whose values are set before the learning process begins.\n\nDetermines how a network is trained and the structure of the network (number of hidden units, learning rate, epochs, etc.)."
        },
        {
          "id": 78,
          "question": "What Will Happen If the Learning Rate Is Set inaccurately (Too Low or Too High)?",
          "answer": "**Too Low**: Training progresses very slowly due to minimal weight updates. Takes many updates before reaching minimum.\n\n**Too High**: Causes divergent behaviour due to drastic weight updates. May fail to converge or even diverge."
        },
        {
          "id": 79,
          "question": "What Is the Difference Between Epoch, Batch, and Iteration in Deep Learning?",
          "answer": "**Epoch**: One iteration over the entire dataset\n\n**Batch**: When we cannot pass entire dataset at once, we divide it into several batches\n\n**Iteration**: Number of batches needed to complete one epoch. (10,000 images / 200 batch size = 50 iterations)"
        },
        {
          "id": 80,
          "question": "What Are the Different Layers on CNN?",
          "answer": "1. **Convolutional Layer**: Performs convolution operation, creating smaller picture windows\n2. **ReLU Layer**: Brings non-linearity, converts negative pixels to zero\n3. **Pooling Layer**: Down-sampling operation that reduces dimensionality\n4. **Fully Connected Layer**: Recognizes and classifies objects in the image"
        },
        {
          "id": 81,
          "question": "What Is Pooling on CNN, and How Does It Work?",
          "answer": "Pooling is used to reduce the spatial dimensions of a CNN.\n\nIt performs down-sampling operations to reduce dimensionality and creates a pooled feature map by sliding a filter matrix over the input matrix."
        },
        {
          "id": 82,
          "question": "What are Recurrent Neural Networks(RNNs)?",
          "answer": "A type of artificial neural networks designed to recognise patterns from sequences of data (time series, stock market, etc.).\n\nRNNs take as input not just the current example but also what they perceived previously in time.\n\nThe decision at time t-1 affects the decision at time t. They have two sources of input: present and recent past."
        },
        {
          "id": 83,
          "question": "How Does an LSTM Network Work?",
          "answer": "Long-Short-Term Memory (LSTM) is a special RNN capable of learning long-term dependencies.\n\n**Three steps**:\n\n1. The network decides what to forget and what to remember\n2. It selectively updates cell state values\n3. The network decides what part of the current state makes it to the output"
        },
        {
          "id": 84,
          "question": "What Is a Multi-layer Perceptron(MLP)?",
          "answer": "Has an input layer, hidden layer(s), and output layer. Same structure as single layer perceptron but with one or more hidden layers.\n\nSingle layer perceptron: only linear separable classes with binary output\nMLP: can classify nonlinear classes\n\nUses backpropagation for supervised learning."
        },
        {
          "id": 85,
          "question": "Explain Gradient Descent.",
          "answer": "**Gradient**: Measures how much the output of a function changes if you change the inputs a little bit. Measures the change in all weights with regard to the change in error.\n\n**Gradient Descent**: A minimization algorithm that minimizes a given function (Activation Function). Like climbing down to the bottom of a valley."
        },
        {
          "id": 86,
          "question": "What is exploding gradients?",
          "answer": "When training an RNN, exponentially growing (very large) error gradients accumulate and result in very large updates to neural network weights.\n\nValues can become so large as to overflow and result in NaN values.\n\nEffect: Model is unstable and unable to learn from training data."
        },
        {
          "id": 87,
          "question": "What is vanishing gradients?",
          "answer": "When training an RNN, your slope can become too small, making training difficult.\n\nLeads to long training times, poor performance, and low accuracy."
        },
        {
          "id": 89,
          "question": "What is Back Propagation and Explain it's Working.",
          "answer": "A training algorithm used for multilayer neural networks that moves error from the end of the network to all weights inside, allowing efficient computation of the gradient.\n\n**Steps**:\n\n1. Forward Propagation of Training Data\n2. Derivatives computed using output and target\n3. Back Propagate for computing derivative of error wrt output activation\n4. Using previously calculated derivatives for output\n5. Update the Weights"
        },
        {
          "id": 90,
          "question": "What are the variants of Back Propagation?",
          "answer": "**Stochastic Gradient Descent**: Uses only a single training example for gradient calculation and parameter update.\n\n**Batch Gradient Descent**: Calculates gradient for whole dataset and performs update at each iteration.\n\n**Mini-batch Gradient Descent**: Most popular. Uses mini-batch of samples instead of single example."
        }
      ]
    }
  ]
}
